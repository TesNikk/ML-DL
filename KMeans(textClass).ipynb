{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0xlOv/px8iZs1PbpkGvUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TesNikk/ML-DL/blob/main/KMeans(textClass).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUvkJp8LHbtu",
        "outputId": "33f303f4-6ba3-45bb-b13e-ea16edd70014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLUSTER  0 :\n",
            "\tSENTENCE  0 :  Cricket is a gentleman's game\n",
            "\tSENTENCE  1 :  Do you watch cricket?\n",
            "\tSENTENCE  2 :  I like Test Match most in cricket\n",
            "CLUSTER  1 :\n",
            "\tSENTENCE  0 :  Champions trophy 2025 is near\n",
            "\tSENTENCE  1 :  Eight teams will compete in Champions trophy 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from pprint import pprint\n",
        "\n",
        "def tokenizer(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(t) for t in tokens if t not in stopwords.words('english')]\n",
        "    return tokens\n",
        "\n",
        "def cluster_sentences(sentences, nb_of_clusters=2):\n",
        "    # create tf-idf again: stopwords -> we filter out common words (I, my, the, and...)\n",
        "    tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words=stopwords.words('english'), lowercase=True)\n",
        "    # builds a tf-idf matrix for the sentences\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "    kmeans = KMeans(n_clusters=nb_of_clusters)\n",
        "    kmeans.fit(tfidf_matrix)\n",
        "    clusters = collections.defaultdict(list)\n",
        "    for i, label in enumerate(kmeans.labels_):\n",
        "        clusters[label].append(i)\n",
        "    return dict(clusters)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # sentences = [\"Quantum physics is quite important in science nowadays.\",\n",
        "    #              \"Software engineering is hotter and hotter topic in the silicon valley\",\n",
        "    #              \"Investing in stocks and trading with them are not that easy\",\n",
        "    #              \"FOREX is the stock market for trading currencies\",\n",
        "    #              \"Warren Buffet is famous for making good investments. He knows stock markets\"]\n",
        "    sentences = [\"Champions trophy 2025 is near\",\n",
        "                 \"Eight teams will compete in Champions trophy 2025\",\n",
        "                 \"Cricket is a gentleman's game\",\n",
        "                 \"Do you watch cricket?\",\n",
        "                 \"I like Test Match most in cricket\"]\n",
        "\n",
        "\n",
        "    nclusters = 2\n",
        "    clusters = cluster_sentences(sentences, nclusters)\n",
        "    for cluster in range(nclusters):\n",
        "        print(\"CLUSTER \", cluster, \":\")\n",
        "        for i, sentence in enumerate(clusters[cluster]):\n",
        "            print(\"\\tSENTENCE \", i, \": \", sentences[sentence])\n"
      ]
    }
  ]
}